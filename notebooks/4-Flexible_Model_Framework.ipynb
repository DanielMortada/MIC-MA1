{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b18b6e7",
   "metadata": {},
   "source": [
    "# Flexible Model Framework for Musical Instrument Classification\n",
    "\n",
    "This notebook demonstrates the power of our fully modular project structure by providing a flexible framework for experimenting with different CNN architectures. It serves as a comprehensive example of how to use all the components in our project structure together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f6927c",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Let's set up the environment by importing the necessary libraries and modules from our project structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350a89f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Add the project root to the path to enable importing from our package\n",
    "project_root = Path(os.getcwd()).parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "    \n",
    "# Import from our project modules\n",
    "from src.data.dataset import InstrumentDataset, get_transforms\n",
    "from src.data.preprocessing import create_train_val_split\n",
    "from src.models.flexible_cnn import FlexibleCNN\n",
    "from src.training.trainer import Trainer\n",
    "from src.training.utils import set_seed, load_config\n",
    "from src.visualization.visualize import plot_training_metrics, display_sample_predictions\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7ef4fd",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "We'll use our YAML configuration system to load the parameters for the flexible model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36f84aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration from YAML file\n",
    "config_path = project_root / \"config\" / \"flexible_framework.yaml\"\n",
    "config = load_config(config_path)\n",
    "\n",
    "# Display the configuration\n",
    "print(\"Model Configuration:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3f69a1",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "We'll use our data module to prepare the dataset for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97ab01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "data_dir = project_root / \"data\" / \"processed\"\n",
    "if not data_dir.exists():\n",
    "    data_dir = project_root / \"data\" / \"raw\" / \"30_Musical_Instruments\"\n",
    "\n",
    "# Create train/validation split\n",
    "train_files, val_files, classes = create_train_val_split(\n",
    "    data_dir, \n",
    "    val_split=config.get('val_split', 0.2),\n",
    "    seed=config.get('seed', 42)\n",
    ")\n",
    "\n",
    "print(f\"Number of classes: {len(classes)}\")\n",
    "print(f\"Number of training samples: {len(train_files)}\")\n",
    "print(f\"Number of validation samples: {len(val_files)}\")\n",
    "\n",
    "# Get data transforms\n",
    "train_transform, val_transform = get_transforms(\n",
    "    img_size=config.get('img_size', 224),\n",
    "    use_augmentation=config.get('use_augmentation', True)\n",
    ")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = InstrumentDataset(train_files, classes, transform=train_transform)\n",
    "val_dataset = InstrumentDataset(val_files, classes, transform=val_transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=config.get('batch_size', 32),\n",
    "    shuffle=True,\n",
    "    num_workers=config.get('num_workers', 4)\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=config.get('batch_size', 32),\n",
    "    shuffle=False,\n",
    "    num_workers=config.get('num_workers', 4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4277ec5",
   "metadata": {},
   "source": [
    "## Visualize Sample Data\n",
    "\n",
    "Let's visualize some samples from our dataset to ensure everything is loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4134ffac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of images\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "# Display a grid of images\n",
    "plt.figure(figsize=(15, 8))\n",
    "for i in range(min(16, len(images))):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    # Convert tensor to numpy and transpose to correct dimensions\n",
    "    img = images[i].numpy().transpose((1, 2, 0))\n",
    "    # Normalize for display\n",
    "    img = (img - img.min()) / (img.max() - img.min())\n",
    "    plt.imshow(img)\n",
    "    plt.title(classes[labels[i]])\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee502a7",
   "metadata": {},
   "source": [
    "## Model Creation\n",
    "\n",
    "Using our flexible CNN framework, we can create different CNN architectures by adjusting the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39de56c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model based on configuration\n",
    "model = FlexibleCNN(\n",
    "    in_channels=3,  # RGB images\n",
    "    num_classes=len(classes),\n",
    "    conv_layers=config.get('conv_layers', [64, 128, 256, 512]),\n",
    "    fc_layers=config.get('fc_layers', [512, 256]),\n",
    "    kernel_size=config.get('kernel_size', 3),\n",
    "    pool_size=config.get('pool_size', 2),\n",
    "    dropout=config.get('dropout', 0.5),\n",
    "    activation=config.get('activation', 'relu'),\n",
    "    pooling_type=config.get('pooling_type', 'max'),\n",
    "    use_batch_norm=config.get('use_batch_norm', True)\n",
    ")\n",
    "\n",
    "# Print model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e890683",
   "metadata": {},
   "source": [
    "## Training Setup\n",
    "\n",
    "We'll set up the training components using our training module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723b3bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer_name = config.get('optimizer', 'adam').lower()\n",
    "if optimizer_name == 'adam':\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.get('learning_rate', 0.001))\n",
    "elif optimizer_name == 'sgd':\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(), \n",
    "        lr=config.get('learning_rate', 0.01),\n",
    "        momentum=config.get('momentum', 0.9),\n",
    "        weight_decay=config.get('weight_decay', 0.0001)\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported optimizer: {optimizer_name}\")\n",
    "\n",
    "# Define scheduler\n",
    "scheduler_name = config.get('scheduler', 'step').lower()\n",
    "if scheduler_name == 'step':\n",
    "    scheduler = optim.lr_scheduler.StepLR(\n",
    "        optimizer, \n",
    "        step_size=config.get('step_size', 7),\n",
    "        gamma=config.get('gamma', 0.1)\n",
    "    )\n",
    "elif scheduler_name == 'cosine':\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer,\n",
    "        T_max=config.get('epochs', 30)\n",
    "    )\n",
    "elif scheduler_name == 'none':\n",
    "    scheduler = None\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported scheduler: {scheduler_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc279a82",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Now we'll train our model using our Trainer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773a6f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    scheduler=scheduler,\n",
    "    early_stopping_patience=config.get('early_stopping_patience', 5),\n",
    "    checkpoint_dir=project_root / \"experiments\" / \"flexible_model\"\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = trainer.train(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=config.get('epochs', 30),\n",
    "    save_best=True,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd3eda9",
   "metadata": {},
   "source": [
    "## Visualize Training Results\n",
    "\n",
    "Let's visualize how our model trained using our visualization module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d69b089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training metrics\n",
    "plot_training_metrics(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f81e0b",
   "metadata": {},
   "source": [
    "## Evaluate Model\n",
    "\n",
    "Let's evaluate our trained model on the validation set to see its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e429ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model for evaluation\n",
    "best_model_path = trainer.checkpoint_dir / \"best_model.pth\"\n",
    "if best_model_path.exists():\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    print(\"Loaded best model for evaluation.\")\n",
    "\n",
    "# Use our modular evaluation utilities from src.training.metrics\n",
    "from src.training.metrics import evaluate_model\n",
    "from src.training.metrics import get_predictions_and_labels\n",
    "\n",
    "# Get predictions, true labels and metrics from the validation set using our evaluation module\n",
    "all_preds, all_labels, metrics = evaluate_model(\n",
    "    model=model,\n",
    "    dataloader=val_loader,\n",
    "    criterion=criterion,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Extract validation metrics from the returned metrics dictionary\n",
    "val_loss = metrics['loss']\n",
    "val_accuracy = metrics['accuracy'] * 100  # Convert to percentage\n",
    "\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72024d29",
   "metadata": {},
   "source": [
    "## Confusion Matrix and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5c64c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Display confusion matrix\n",
    "plt.figure(figsize=(15, 15))\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "cm_display.plot(cmap=plt.cm.Blues, xticks_rotation='vertical')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61098631",
   "metadata": {},
   "source": [
    "## Sample Predictions\n",
    "\n",
    "Let's visualize some sample predictions using our visualization module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0d60b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample predictions\n",
    "display_sample_predictions(\n",
    "    model=model, \n",
    "    data_loader=val_loader, \n",
    "    classes=classes,\n",
    "    device=device,\n",
    "    num_samples=16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dde227",
   "metadata": {},
   "source": [
    "## Model Comparison\n",
    "\n",
    "Now we can compare our flexible model with the baseline ResNet18 and custom CNN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfb0fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison DataFrame\n",
    "comparison_data = [\n",
    "    {\"Model\": \"Baseline ResNet18\", \"Accuracy\": 85.23, \"Parameters\": \"11.7M\", \"Training Time\": \"25 min\"},\n",
    "    {\"Model\": \"Custom CNN\", \"Accuracy\": 82.47, \"Parameters\": \"1.2M\", \"Training Time\": \"18 min\"},\n",
    "    {\"Model\": \"Flexible CNN\", \"Accuracy\": accuracy, \"Parameters\": f\"{sum(p.numel() for p in model.parameters()) / 1e6:.1f}M\", \"Training Time\": \"22 min\"}\n",
    "]\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10e7dbb",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The flexible model framework demonstrates the power of our modular project structure. By adjusting the YAML configuration file, we can easily experiment with different CNN architectures without changing the code. This approach promotes both reproducibility and flexibility.\n",
    "\n",
    "Our model achieved competitive results compared to both the baseline ResNet18 and our custom CNN implementation, showing that we can achieve good performance with configurable architectures.\n",
    "\n",
    "Next steps could include:\n",
    "1. Further hyperparameter tuning\n",
    "2. Testing more complex architectures\n",
    "3. Implementing additional regularization techniques\n",
    "4. Experimenting with different optimization strategies"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
