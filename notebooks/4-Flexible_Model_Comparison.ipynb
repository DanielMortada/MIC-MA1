{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b00a405d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU detected. Will run models sequentially.\n"
     ]
    }
   ],
   "source": [
    "# GPU Parallelism Utilities\n",
    "\n",
    "import threading\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DataParallel\n",
    "from queue import Queue\n",
    "import gc\n",
    "\n",
    "# 1. DataParallel Wrapper for models\n",
    "def apply_data_parallel(model, device):\n",
    "    \"\"\"Apply DataParallel to split batches across GPU threads if using CUDA\"\"\"\n",
    "    if torch.cuda.is_available() and 'cuda' in str(device):\n",
    "        return DataParallel(model).to(device)\n",
    "    return model.to(device)\n",
    "\n",
    "# 2. Memory Management Utilities\n",
    "def get_gpu_memory_info():\n",
    "    \"\"\"Get GPU memory usage information\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        # Get stats for the current device\n",
    "        device_idx = torch.cuda.current_device()\n",
    "        stats = torch.cuda.memory_stats(device_idx)\n",
    "        # Find total, allocated, and free memory\n",
    "        total_memory = torch.cuda.get_device_properties(device_idx).total_memory / (1024**3)  # GB\n",
    "        allocated = stats[\"allocated_bytes.all.current\"] / (1024**3)  # GB\n",
    "        free_memory = total_memory - allocated\n",
    "        return {\n",
    "            \"total_memory_gb\": total_memory,\n",
    "            \"allocated_memory_gb\": allocated,\n",
    "            \"free_memory_gb\": free_memory,\n",
    "            \"device\": torch.cuda.get_device_name(device_idx)\n",
    "        }\n",
    "    return {\"device\": \"CPU\", \"total_memory_gb\": 0, \"allocated_memory_gb\": 0, \"free_memory_gb\": 0}\n",
    "\n",
    "def clear_gpu_memory():\n",
    "    \"\"\"Aggressively clear GPU memory\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "# 3. Concurrent Model Training with Threading\n",
    "class ConcurrentTrainer:\n",
    "    \"\"\"Class for training multiple models concurrently on a single GPU\"\"\"\n",
    "    def __init__(self, configs, dataloaders, device, max_concurrent=2):\n",
    "        self.configs = configs\n",
    "        self.dataloaders = dataloaders\n",
    "        self.device = device\n",
    "        self.max_concurrent = max_concurrent\n",
    "        self.results = []\n",
    "        self.lock = threading.Lock()\n",
    "        self.active_count = 0\n",
    "    \n",
    "    def _train_model_thread(self, config, idx, result_queue):\n",
    "        \"\"\"Thread worker function to train a model\"\"\"\n",
    "        try:\n",
    "            with self.lock:  # Track active thread count\n",
    "                self.active_count += 1\n",
    "            \n",
    "            # Print memory info before training\n",
    "            memory_info = get_gpu_memory_info()\n",
    "            print(f\"\\nStarting training for {config['name']} | \"  \n",
    "                  f\"GPU Memory: {memory_info['free_memory_gb']:.2f}GB free\")\n",
    "            \n",
    "            # Train model\n",
    "            results = train_model_with_config(config, self.dataloaders, self.device)\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            eval_metrics = evaluate_model_on_test(\n",
    "                results['model'],\n",
    "                test_loader,\n",
    "                self.device,\n",
    "                class_names,\n",
    "                model_name=config['name']\n",
    "            )\n",
    "            \n",
    "            # Combine results\n",
    "            complete_results = {\n",
    "                'model_name': config['name'],\n",
    "                'architecture': config['model']['architecture'],\n",
    "                'config': config,\n",
    "                'training_time': results['training_time'],\n",
    "                'best_val_acc': results['training_stats']['best_val_acc'],\n",
    "                'best_epoch': results['training_stats']['best_epoch'],\n",
    "                'test_accuracy': eval_metrics['accuracy'],\n",
    "                'f1_score': eval_metrics['f1_score'],\n",
    "                'precision': eval_metrics['precision'],\n",
    "                'recall': eval_metrics['recall']\n",
    "            }\n",
    "            \n",
    "            # Save model\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            if IN_COLAB:\n",
    "                save_dir = os.path.join(project_root, \"experiments\", f\"{config['name'].lower().replace(' ', '_')}_{timestamp}\")\n",
    "            else:\n",
    "                save_dir = os.path.join(project_root, \"experiments\", f\"{config['name'].lower().replace(' ', '_')}_{timestamp}\")\n",
    "            \n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "            save_path = os.path.join(save_dir, f\"{config['name'].lower().replace(' ', '_')}.pt\")\n",
    "            \n",
    "            save_model(\n",
    "                results['model'],\n",
    "                config,\n",
    "                save_path,\n",
    "                metrics={\n",
    "                    'accuracy': eval_metrics['accuracy'],\n",
    "                    'f1_macro': eval_metrics['f1_score'],\n",
    "                    'best_val_acc': results['training_stats']['best_val_acc'],\n",
    "                    'best_epoch': results['training_stats']['best_epoch']\n",
    "                },\n",
    "                epoch=results['training_stats']['best_epoch']\n",
    "            )\n",
    "            \n",
    "            print(f\"Model saved to {save_path}\")\n",
    "            \n",
    "            # Add to results queue\n",
    "            result_queue.put((idx, complete_results))\n",
    "            \n",
    "            # Clear GPU memory\n",
    "            del results['model']\n",
    "            clear_gpu_memory()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error training {config['name']}: {e}\")\n",
    "            result_queue.put((idx, None))\n",
    "            \n",
    "        finally:\n",
    "            with self.lock:  # Update active thread count\n",
    "                self.active_count -= 1\n",
    "    \n",
    "    def train_all_models(self):\n",
    "        \"\"\"Train all models with controlled concurrency\"\"\"\n",
    "        memory_info = get_gpu_memory_info()\n",
    "        print(f\"\\nGPU Memory Information before training:\")\n",
    "        print(f\"Device: {memory_info['device']}\")\n",
    "        print(f\"Total Memory: {memory_info['total_memory_gb']:.2f} GB\")\n",
    "        print(f\"Allocated Memory: {memory_info['allocated_memory_gb']:.2f} GB\")\n",
    "        print(f\"Free Memory: {memory_info['free_memory_gb']:.2f} GB\")\n",
    "        \n",
    "        result_queue = Queue()\n",
    "        threads = []\n",
    "        results = [None] * len(self.configs)\n",
    "        \n",
    "        # Create a thread for each model configuration\n",
    "        for idx, config in enumerate(self.configs):\n",
    "            thread = threading.Thread(\n",
    "                target=self._train_model_thread,\n",
    "                args=(config, idx, result_queue)\n",
    "            )\n",
    "            threads.append(thread)\n",
    "        \n",
    "        # Start threads with controlled concurrency\n",
    "        running_threads = []\n",
    "        for thread in threads:\n",
    "            # Wait if we've reached max concurrent threads\n",
    "            while self.active_count >= self.max_concurrent:\n",
    "                # Check if any results are ready\n",
    "                if not result_queue.empty():\n",
    "                    idx, result = result_queue.get()\n",
    "                    if result is not None:\n",
    "                        results[idx] = result\n",
    "                time.sleep(1)  # Sleep briefly before checking again\n",
    "            \n",
    "            # Start the thread\n",
    "            thread.start()\n",
    "            running_threads.append(thread)\n",
    "        \n",
    "        # Collect remaining results\n",
    "        for thread in running_threads:\n",
    "            thread.join()\n",
    "        \n",
    "        # Get any remaining results\n",
    "        while not result_queue.empty():\n",
    "            idx, result = result_queue.get()\n",
    "            if result is not None:\n",
    "                results[idx] = result\n",
    "        \n",
    "        # Filter out any None results (from errors)\n",
    "        self.results = [r for r in results if r is not None]\n",
    "        return self.results\n",
    "\n",
    "# Let user decide how many concurrent models to train based on their GPU\n",
    "def check_gpu_and_suggest_concurrency():\n",
    "    \"\"\"Check GPU and suggest concurrency level based on memory\"\"\"\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"No GPU detected. Will run models sequentially.\")\n",
    "        return 1\n",
    "    \n",
    "    memory_info = get_gpu_memory_info()\n",
    "    total_gb = memory_info['total_memory_gb']\n",
    "    print(f\"\\nGPU: {memory_info['device']}\")\n",
    "    print(f\"Total Memory: {total_gb:.2f} GB\")\n",
    "    print(f\"Free Memory: {memory_info['free_memory_gb']:.2f} GB\")\n",
    "    \n",
    "    # Suggestion based on total memory\n",
    "    if total_gb >= 24:  # High-end GPUs\n",
    "        suggested = 3\n",
    "    elif total_gb >= 12:  # Mid-range GPUs\n",
    "        suggested = 2\n",
    "    else:  # Low-end GPUs\n",
    "        suggested = 1\n",
    "    \n",
    "    print(f\"\\nBased on your GPU memory, suggested concurrent models: {suggested}\")\n",
    "    return suggested\n",
    "\n",
    "# Check GPU and get recommended concurrency\n",
    "concurrent_models = check_gpu_and_suggest_concurrency()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47939b7f",
   "metadata": {},
   "source": [
    "# Flexible CNN Architecture Comparison for Musical Instrument Classification\n",
    "\n",
    "This notebook implements an approach to compare different configurations of our CustomCNN model using the flexible framework. We'll train and evaluate multiple CNN architectures to find the optimal configuration for musical instrument classification.\n",
    "\n",
    "## Approach Overview\n",
    "\n",
    "1. **Environment Setup**: Configure the Colab environment and import necessary modules\n",
    "2. **Dataset Preparation**: Load and preprocess the dataset once for all models\n",
    "3. **Model Configurations**: Define multiple CustomCNN variants with different architectures\n",
    "4. **Sequential Training**: Train each model variant and track performance metrics\n",
    "5. **Comparison Analysis**: Compare model variants and identify the best-performing architecture\n",
    "6. **Visualization**: Create comparative visualizations of model performance\n",
    "\n",
    "We'll use our `FlexibleCNN` model which allows us to experiment with different architectures through configuration rather than code changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11157bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Add project root to path to enable imports from src\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "# Check if we're running in Google Colab\n",
    "import importlib.util\n",
    "IN_COLAB = importlib.util.find_spec(\"google.colab\") is not None\n",
    "\n",
    "# Get the current directory\n",
    "current_dir = os.getcwd()\n",
    "print(f\"Current directory: {current_dir}\")\n",
    "\n",
    "# Import our project modules\n",
    "try:\n",
    "    from scripts.colab_integration import setup_colab_environment, check_gpu\n",
    "    from src.data.preprocessing import get_preprocessing_transforms\n",
    "    from src.data.augmentation import AdvancedAugmentation\n",
    "    from src.data.dataloader import load_datasets\n",
    "    from src.models.baseline import get_resnet18_model, unfreeze_layers\n",
    "    from src.models.custom_cnn import create_custom_cnn\n",
    "    from src.models.flexible_cnn import FlexibleCNN, create_flexible_cnn\n",
    "    from src.training.trainer import train_model, evaluate_model\n",
    "    from src.training.metrics import compute_metrics, get_confusion_matrix\n",
    "    from src.visualization.plotting import plot_training_history, plot_confusion_matrix, plot_sample_predictions, plot_sample_images\n",
    "    from src.models.model_utils import save_model\n",
    "    \n",
    "    print(\"Successfully imported project modules\")\n",
    "except Exception as e:\n",
    "    print(f\"Error importing project modules: {e}\")\n",
    "    print(\"Please ensure all required modules are available\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Add project root to path to ensure imports work correctly\n",
    "    project_root = os.path.join(current_dir, \"MIC-MA1\")\n",
    "    sys.path.insert(0, project_root)\n",
    "    print(f\"Project root added to path: {project_root}\")\n",
    "    print(\"ðŸš€ Running in Google Colab - setting up environment...\")\n",
    "    setup_colab_environment()  # This handles all the Colab-specific setup\n",
    "else:\n",
    "    # Running locally\n",
    "    project_root = str(Path(current_dir).parent)\n",
    "    sys.path.append(project_root)\n",
    "    print(f\"Running locally, project root: {project_root}\")\n",
    "    print(\"ðŸ’» Running locally - using local environment\")\n",
    "\n",
    "# Check for TPU and GPU availability\n",
    "try:\n",
    "    import torch_xla\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    device = xm.xla_device()\n",
    "    print(\"Using TPU:\", device)\n",
    "except ImportError:\n",
    "    device = check_gpu()  # Your utility function for GPU detection\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd67dd48",
   "metadata": {},
   "source": [
    "## 1. Dataset Preparation\n",
    "\n",
    "We'll load our dataset once and use it for all model variants to ensure fair comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11d1124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default data configuration\n",
    "data_config = {\n",
    "    'img_size': 224,\n",
    "    'batch_size': 32,\n",
    "    'num_workers': 2 if IN_COLAB else 4,\n",
    "    'pin_memory': True,\n",
    "    'augmentation_strength': 'medium'\n",
    "}\n",
    "\n",
    "# Set data directory\n",
    "if IN_COLAB:\n",
    "    # Adjust path based on your Google Drive structure\n",
    "    data_dir = os.path.join(project_root, \"data/raw/30_Musical_Instruments\")\n",
    "    if not os.path.exists(data_dir):\n",
    "        print(\"âš ï¸ Dataset not found in the expected location\")\n",
    "        print(\"Please upload the dataset to the correct location in Google Drive\")\n",
    "else:\n",
    "    data_dir = os.path.join(project_root, \"data/raw/30_Musical_Instruments\")\n",
    "\n",
    "print(f\"Using data directory: {data_dir}\")\n",
    "\n",
    "# Get advanced transforms with the specified strength\n",
    "print(f\"Using advanced augmentation with strength: {data_config['augmentation_strength']}\")\n",
    "transforms = AdvancedAugmentation.get_advanced_transforms(\n",
    "    img_size=data_config['img_size'],\n",
    "    augmentation_strength=data_config['augmentation_strength']\n",
    ")\n",
    "\n",
    "# Load datasets using our utility function\n",
    "try:\n",
    "    data = load_datasets(\n",
    "        data_dir=data_dir,\n",
    "        transforms=transforms,\n",
    "        batch_size=data_config['batch_size'],\n",
    "        num_workers=data_config['num_workers'],\n",
    "        pin_memory=data_config['pin_memory']\n",
    "    )\n",
    "    \n",
    "    # Access the components\n",
    "    train_loader = data['dataloaders']['train']\n",
    "    valid_loader = data['dataloaders']['val']\n",
    "    test_loader = data['dataloaders']['test']\n",
    "    \n",
    "    # Get class information\n",
    "    class_names = list(data['class_mappings']['idx_to_class'].values())\n",
    "    num_classes = data['num_classes']\n",
    "    \n",
    "    print(f\"\\nDataset loaded successfully:\")\n",
    "    print(f\"- Number of classes: {num_classes}\")\n",
    "    print(f\"- Training samples: {len(data['datasets']['train'])}\")\n",
    "    print(f\"- Validation samples: {len(data['datasets']['val'])}\")\n",
    "    print(f\"- Test samples: {len(data['datasets']['test'])}\")\n",
    "    \n",
    "    # Display a few class names\n",
    "    print(f\"\\nSample classes: {class_names[:5]}...\")\n",
    "    \n",
    "    # Prepare dataloaders dictionary for training\n",
    "    dataloaders = {\n",
    "        'train': train_loader,\n",
    "        'val': valid_loader\n",
    "    }\n",
    "    \n",
    "    # Visualize some sample images\n",
    "    print(\"\\nSample training images:\")\n",
    "    plot_sample_images(\n",
    "        dataset=data['datasets']['train'],\n",
    "        class_mapping=data['class_mappings']['idx_to_class'],\n",
    "        num_images=5,\n",
    "        title=\"Sample Training Images\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error loading datasets: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aba8592",
   "metadata": {},
   "source": [
    "## 2. Model Configurations\n",
    "\n",
    "We'll define multiple configurations for our CustomCNN models to compare:\n",
    "\n",
    "1. **Base Custom CNN** - The original CustomCNN architecture\n",
    "2. **Deeper Custom CNN** - A deeper architecture with an additional convolutional block\n",
    "3. **Wider Custom CNN** - A wider architecture with more filters in each layer\n",
    "4. **Regularized Custom CNN** - A variant with stronger regularization\n",
    "5. **ResNet18 Baseline** - For comparison with a standard architecture\n",
    "\n",
    "We'll create these configurations directly in the notebook for simplicity, but they are based on our YAML configuration files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf59aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define various model configurations\n",
    "\n",
    "# 1. Base Custom CNN configuration\n",
    "base_cnn_config = {\n",
    "    'model': {\n",
    "        'architecture': 'flexible_cnn',\n",
    "        'input_channels': 3,\n",
    "        'num_classes': num_classes,\n",
    "        'conv_layers': [32, 64, 128, 256, 512],\n",
    "        'fc_layers': [512, 256],\n",
    "        'kernel_size': 3,\n",
    "        'pool_size': 2,\n",
    "        'dropout': 0.5,\n",
    "        'activation': 'relu',\n",
    "        'pooling_type': 'max',\n",
    "        'use_batch_norm': True\n",
    "    },\n",
    "    'training': {\n",
    "        'num_epochs': 30,\n",
    "        'batch_size': 32,\n",
    "        'optimizer': {\n",
    "            'name': 'adamw',\n",
    "            'learning_rate': 0.001,\n",
    "            'weight_decay': 0.0005\n",
    "        },\n",
    "        'scheduler': {\n",
    "            'name': 'onecycle',\n",
    "            'max_lr': 0.01\n",
    "        }\n",
    "    },\n",
    "    'name': 'Base CNN'\n",
    "}\n",
    "\n",
    "# 2. Deeper Custom CNN configuration\n",
    "deeper_cnn_config = {\n",
    "    'model': {\n",
    "        'architecture': 'flexible_cnn',\n",
    "        'input_channels': 3,\n",
    "        'num_classes': num_classes,\n",
    "        'conv_layers': [32, 64, 128, 256, 512, 512],  # Added an extra layer\n",
    "        'fc_layers': [512, 256],\n",
    "        'kernel_size': 3,\n",
    "        'pool_size': 2,\n",
    "        'dropout': [0.1, 0.2, 0.3, 0.4, 0.5, 0.5, 0.5],  # Progressive dropout\n",
    "        'activation': 'relu',\n",
    "        'pooling_type': 'max',\n",
    "        'use_batch_norm': True\n",
    "    },\n",
    "    'training': {\n",
    "        'num_epochs': 30,\n",
    "        'batch_size': 32,\n",
    "        'optimizer': {\n",
    "            'name': 'adamw',\n",
    "            'learning_rate': 0.001,\n",
    "            'weight_decay': 0.0005\n",
    "        },\n",
    "        'scheduler': {\n",
    "            'name': 'onecycle',\n",
    "            'max_lr': 0.01\n",
    "        }\n",
    "    },\n",
    "    'name': 'Deeper CNN'\n",
    "}\n",
    "\n",
    "# 3. Wider Custom CNN configuration\n",
    "wider_cnn_config = {\n",
    "    'model': {\n",
    "        'architecture': 'flexible_cnn',\n",
    "        'input_channels': 3,\n",
    "        'num_classes': num_classes,\n",
    "        'conv_layers': [64, 128, 256, 512, 1024],  # Doubled filter count in last layer\n",
    "        'fc_layers': [1024, 512],  # Wider fully connected layers\n",
    "        'kernel_size': 3,\n",
    "        'pool_size': 2,\n",
    "        'dropout': 0.5,\n",
    "        'activation': 'relu',\n",
    "        'pooling_type': 'max',\n",
    "        'use_batch_norm': True\n",
    "    },\n",
    "    'training': {\n",
    "        'num_epochs': 30,\n",
    "        'batch_size': 32,\n",
    "        'optimizer': {\n",
    "            'name': 'adamw',\n",
    "            'learning_rate': 0.001,\n",
    "            'weight_decay': 0.0005\n",
    "        },\n",
    "        'scheduler': {\n",
    "            'name': 'onecycle',\n",
    "            'max_lr': 0.01\n",
    "        }\n",
    "    },\n",
    "    'name': 'Wider CNN'\n",
    "}\n",
    "\n",
    "# 4. Regularized Custom CNN configuration\n",
    "regularized_cnn_config = {\n",
    "    'model': {\n",
    "        'architecture': 'flexible_cnn',\n",
    "        'input_channels': 3,\n",
    "        'num_classes': num_classes,\n",
    "        'conv_layers': [32, 64, 128, 256, 512],\n",
    "        'fc_layers': [512, 256],\n",
    "        'kernel_size': 3,\n",
    "        'pool_size': 2,\n",
    "        'dropout': [0.2, 0.3, 0.4, 0.5, 0.6, 0.6, 0.6],  # Higher dropout rates\n",
    "        'activation': 'relu',\n",
    "        'pooling_type': 'max',\n",
    "        'use_batch_norm': True\n",
    "    },\n",
    "    'training': {\n",
    "        'num_epochs': 30,\n",
    "        'batch_size': 32,\n",
    "        'optimizer': {\n",
    "            'name': 'adamw',\n",
    "            'learning_rate': 0.001,\n",
    "            'weight_decay': 0.001  # Increased weight decay\n",
    "        },\n",
    "        'scheduler': {\n",
    "            'name': 'onecycle',\n",
    "            'max_lr': 0.01\n",
    "        }\n",
    "    },\n",
    "    'name': 'Regularized CNN'\n",
    "}\n",
    "\n",
    "# 5. ResNet18 Baseline (for comparison)\n",
    "resnet18_config = {\n",
    "    'model': {\n",
    "        'architecture': 'resnet18',\n",
    "        'pretrained': True,\n",
    "        'feature_extracting': False,  # Full fine-tuning\n",
    "        'num_classes': num_classes,\n",
    "        'unfreeze_layers': ['layer4', 'fc']\n",
    "    },\n",
    "    'training': {\n",
    "        'num_epochs': 30,\n",
    "        'batch_size': 32,\n",
    "        'optimizer': {\n",
    "            'name': 'adamw',\n",
    "            'learning_rate': 0.001,\n",
    "            'weight_decay': 0.0005\n",
    "        },\n",
    "        'scheduler': {\n",
    "            'name': 'onecycle',\n",
    "            'max_lr': 0.01\n",
    "        }\n",
    "    },\n",
    "    'name': 'ResNet18'\n",
    "}\n",
    "\n",
    "# Create a list of configurations to iterate through\n",
    "model_configs = [\n",
    "    base_cnn_config,\n",
    "    deeper_cnn_config,\n",
    "    wider_cnn_config, \n",
    "    regularized_cnn_config,\n",
    "    resnet18_config\n",
    "]\n",
    "\n",
    "# Print configuration summary\n",
    "print(\"Model configurations to compare:\")\n",
    "for config in model_configs:\n",
    "    if config['model']['architecture'] == 'flexible_cnn':\n",
    "        print(f\"\\n{config['name']}:\")\n",
    "        print(f\"- Conv layers: {config['model']['conv_layers']}\")\n",
    "        print(f\"- FC layers: {config['model']['fc_layers']}\")\n",
    "        print(f\"- Dropout: {config['model']['dropout']}\")\n",
    "    else:\n",
    "        print(f\"\\n{config['name']}:\")\n",
    "        print(f\"- Architecture: {config['model']['architecture']}\")\n",
    "        print(f\"- Pretrained: {config['model']['pretrained']}\")\n",
    "        print(f\"- Feature extracting: {config['model']['feature_extracting']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aae81a3",
   "metadata": {},
   "source": [
    "## 3. Model Creation and Training Functions\n",
    "\n",
    "Let's create utility functions to instantiate models and train them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e842914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(config, device):\n",
    "    \"\"\"Create model based on configuration\"\"\"\n",
    "    model_config = config['model']\n",
    "    architecture = model_config.get('architecture', 'resnet18').lower()\n",
    "    \n",
    "    if architecture == 'resnet18':\n",
    "        pretrained = model_config.get('pretrained', True)\n",
    "        feature_extracting = model_config.get('feature_extracting', True)\n",
    "        \n",
    "        model = get_resnet18_model(\n",
    "            num_classes=model_config['num_classes'],\n",
    "            pretrained=pretrained,\n",
    "            feature_extracting=feature_extracting\n",
    "        )\n",
    "        \n",
    "        # Unfreeze specific layers if specified\n",
    "        if not feature_extracting and 'unfreeze_layers' in model_config:\n",
    "            model, _ = unfreeze_layers(model, model_config['unfreeze_layers'])\n",
    "            \n",
    "    elif architecture == 'custom_cnn':\n",
    "        model = create_custom_cnn(\n",
    "            num_classes=model_config['num_classes'],\n",
    "            input_channels=model_config.get('input_channels', 3)\n",
    "        )\n",
    "    elif architecture == 'flexible_cnn':\n",
    "        model = create_flexible_cnn(config)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported architecture: {architecture}\")\n",
    "    \n",
    "    return model.to(device)\n",
    "\n",
    "def create_optimizer(config, model_parameters):\n",
    "    \"\"\"Create optimizer based on configuration\"\"\"\n",
    "    optimizer_config = config['training']['optimizer']\n",
    "    optimizer_name = optimizer_config.get('name', 'adam').lower()\n",
    "    lr = optimizer_config.get('learning_rate', 0.001)\n",
    "    weight_decay = optimizer_config.get('weight_decay', 0.0001)\n",
    "    \n",
    "    if optimizer_name == 'adam':\n",
    "        return torch.optim.Adam(\n",
    "            model_parameters,\n",
    "            lr=lr,\n",
    "            weight_decay=weight_decay,\n",
    "            betas=(\n",
    "                optimizer_config.get('beta1', 0.9),\n",
    "                optimizer_config.get('beta2', 0.999)\n",
    "            )\n",
    "        )\n",
    "    elif optimizer_name == 'adamw':\n",
    "        return torch.optim.AdamW(\n",
    "            model_parameters,\n",
    "            lr=lr,\n",
    "            weight_decay=weight_decay,\n",
    "            betas=(\n",
    "                optimizer_config.get('beta1', 0.9),\n",
    "                optimizer_config.get('beta2', 0.999)\n",
    "            )\n",
    "        )\n",
    "    elif optimizer_name == 'sgd':\n",
    "        return torch.optim.SGD(\n",
    "            model_parameters,\n",
    "            lr=lr,\n",
    "            momentum=optimizer_config.get('momentum', 0.9),\n",
    "            weight_decay=weight_decay,\n",
    "            nesterov=optimizer_config.get('nesterov', True)\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported optimizer: {optimizer_name}\")\n",
    "\n",
    "def create_scheduler(config, optimizer, steps_per_epoch=None):\n",
    "    \"\"\"Create learning rate scheduler based on configuration\"\"\"\n",
    "    scheduler_config = config['training'].get('scheduler', {})\n",
    "    scheduler_name = scheduler_config.get('name', '').lower()\n",
    "    \n",
    "    if not scheduler_name:\n",
    "        return None\n",
    "        \n",
    "    if scheduler_name == 'step':\n",
    "        return torch.optim.lr_scheduler.StepLR(\n",
    "            optimizer,\n",
    "            step_size=scheduler_config.get('step_size', 7),\n",
    "            gamma=scheduler_config.get('gamma', 0.1)\n",
    "        )\n",
    "    elif scheduler_name == 'cosine':\n",
    "        return torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer,\n",
    "            T_max=scheduler_config.get('t_max', config['training']['num_epochs']),\n",
    "            eta_min=scheduler_config.get('eta_min', 0)\n",
    "        )\n",
    "    elif scheduler_name == 'plateau':\n",
    "        return torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='min',\n",
    "            factor=scheduler_config.get('factor', 0.1),\n",
    "            patience=scheduler_config.get('patience', 5),\n",
    "            min_lr=scheduler_config.get('min_lr', 1e-6)\n",
    "        )\n",
    "    elif scheduler_name == 'onecycle' and steps_per_epoch:\n",
    "        return torch.optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=scheduler_config.get('max_lr', 0.01),\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            epochs=config['training']['num_epochs'],\n",
    "            pct_start=scheduler_config.get('pct_start', 0.3)\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Warning: Scheduler {scheduler_name} not configured correctly, using no scheduler\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498453c5",
   "metadata": {},
   "source": [
    "## 4. Function to Train Models and Track Results\n",
    "\n",
    "Now we'll create a function to train a model with a given configuration and track the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e670a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_config(config, dataloaders, device):\n",
    "    \"\"\"\n",
    "    Train a model with the specified configuration and return the results\n",
    "    \n",
    "    Args:\n",
    "        config (dict): Model and training configuration\n",
    "        dataloaders (dict): Dictionary with 'train' and 'val' dataloaders\n",
    "        device (torch.device): Device to train on\n",
    "        \n",
    "    Returns:\n",
    "        dict: Results including model, metrics, and training time\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Training model: {config['name']}\")\n",
    "    print(f\"Architecture: {config['model']['architecture']}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Record start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create model\n",
    "    model = create_model(config, device)\n",
    "    \n",
    "    # Create optimizer\n",
    "    optimizer = create_optimizer(config, model.parameters())\n",
    "    \n",
    "    # Create scheduler\n",
    "    scheduler = create_scheduler(\n",
    "        config,\n",
    "        optimizer,\n",
    "        steps_per_epoch=len(dataloaders['train'])\n",
    "    )\n",
    "    \n",
    "    # Set up loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Train model\n",
    "    model, history, training_stats = train_model(\n",
    "        model,\n",
    "        dataloaders,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler=scheduler,\n",
    "        num_epochs=config['training']['num_epochs'],\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # Record training time\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Save results\n",
    "    results = {\n",
    "        'model': model,\n",
    "        'config': config,\n",
    "        'history': history,\n",
    "        'training_stats': training_stats,\n",
    "        'training_time': training_time\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nTraining completed in {training_time:.2f} seconds\")\n",
    "    print(f\"Best validation accuracy: {training_stats['best_val_acc']:.4f} at epoch {training_stats['best_epoch']}\")\n",
    "    \n",
    "    # Plot training history\n",
    "    plot_training_history(history)\n",
    "    \n",
    "    # Return results for comparison\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4cb77c",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation Function\n",
    "\n",
    "Next, we'll create a function to evaluate models on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffda0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_on_test(model, test_loader, device, class_names, model_name=None):\n",
    "    \"\"\"\n",
    "    Evaluate a trained model on the test set\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): Trained model\n",
    "        test_loader (DataLoader): Test data loader\n",
    "        device (torch.device): Device to evaluate on\n",
    "        class_names (list): List of class names\n",
    "        model_name (str): Name of the model for display\n",
    "        \n",
    "    Returns:\n",
    "        dict: Evaluation metrics\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Evaluating model{': ' + model_name if model_name else ''} on test set\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Evaluate model\n",
    "    test_accuracy, test_preds, test_labels = evaluate_model(\n",
    "        model,\n",
    "        test_loader,\n",
    "        device,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # Compute metrics\n",
    "    metrics = compute_metrics(test_labels, test_preds, class_names)\n",
    "    \n",
    "    print(f\"Test Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(f\"Macro-average F1 Score: {metrics['macro_avg']['f1']:.4f}\")\n",
    "    print(f\"Macro-average Precision: {metrics['macro_avg']['precision']:.4f}\")\n",
    "    print(f\"Macro-average Recall: {metrics['macro_avg']['recall']:.4f}\")\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    cm = get_confusion_matrix(test_labels, test_preds)\n",
    "    plot_confusion_matrix(\n",
    "        cm, \n",
    "        class_names, \n",
    "        figsize=(12, 10), \n",
    "        fontsize=8,\n",
    "        title=f\"Confusion Matrix - {model_name if model_name else 'Model'}\"\n",
    "    )\n",
    "    \n",
    "    # Return metrics\n",
    "    return {\n",
    "        'accuracy': metrics['accuracy'],\n",
    "        'f1_score': metrics['macro_avg']['f1'],\n",
    "        'precision': metrics['macro_avg']['precision'],\n",
    "        'recall': metrics['macro_avg']['recall'],\n",
    "        'predictions': test_preds,\n",
    "        'labels': test_labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebdf5a1",
   "metadata": {},
   "source": [
    "## 6. GPU Parallelism Strategies\n",
    "\n",
    "To effectively utilize a single GPU's multiple cores and parallel processing capabilities, we can employ several strategies:\n",
    "\n",
    "1. **DataParallel for Batch Splitting**: PyTorch's DataParallel splits batches across available GPU threads\n",
    "2. **Memory-Efficient Training**: Train models in sequence but with optimized batch sizes\n",
    "3. **Concurrent Training with Memory Management**: Use Python's threading to manage multiple models training concurrently\n",
    "\n",
    "Let's implement these approaches:\n",
    "\n",
    "## 6. Sequential Training of Models\n",
    "\n",
    "Now let's train each model configuration sequentially and collect results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b859e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Apply DataParallel to models for better utilization of single GPU\n",
    "print(\"\\nApplying DataParallel to models for batch parallelism on GPU\")\n",
    "\n",
    "# Function to train with DataParallel\n",
    "def train_with_data_parallel():\n",
    "    all_results = []\n",
    "    \n",
    "    # Train each model configuration sequentially but with DataParallel\n",
    "    for config in model_configs:\n",
    "        try:\n",
    "            # Temporarily increase batch size for better parallelism if memory allows\n",
    "            original_batch_size = config['training'].get('batch_size', 32)\n",
    "            memory_info = get_gpu_memory_info()\n",
    "            \n",
    "            # If enough GPU memory, double the batch size for DataParallel\n",
    "            if memory_info['free_memory_gb'] > 4 and torch.cuda.device_count() > 0:\n",
    "                config['training']['batch_size'] = original_batch_size * 2\n",
    "                print(f\"\\nIncreased batch size to {config['training']['batch_size']} for {config['name']}\")\n",
    "            \n",
    "            # Create model with DataParallel\n",
    "            model = create_model(config, device)\n",
    "            model = apply_data_parallel(model, device)\n",
    "            \n",
    "            # Create optimizer and scheduler\n",
    "            optimizer = create_optimizer(config, model.parameters())\n",
    "            scheduler = create_scheduler(\n",
    "                config,\n",
    "                optimizer,\n",
    "                steps_per_epoch=len(dataloaders['train'])\n",
    "            )\n",
    "            \n",
    "            # Set up loss function\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            \n",
    "            # Record start time\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Train model\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"Training model with DataParallel: {config['name']}\")\n",
    "            print(f\"{'='*80}\")\n",
    "            \n",
    "            model, history, training_stats = train_model(\n",
    "                model,\n",
    "                dataloaders,\n",
    "                criterion,\n",
    "                optimizer,\n",
    "                device,\n",
    "                scheduler=scheduler,\n",
    "                num_epochs=config['training']['num_epochs'],\n",
    "                verbose=True\n",
    "            )\n",
    "            \n",
    "            # Record training time\n",
    "            training_time = time.time() - start_time\n",
    "            \n",
    "            # Restore original batch size\n",
    "            config['training']['batch_size'] = original_batch_size\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            eval_metrics = evaluate_model_on_test(\n",
    "                model,\n",
    "                test_loader,\n",
    "                device,\n",
    "                class_names,\n",
    "                model_name=config['name']\n",
    "            )\n",
    "            \n",
    "            # Combine results\n",
    "            complete_results = {\n",
    "                'model_name': config['name'],\n",
    "                'architecture': config['model']['architecture'],\n",
    "                'config': config,\n",
    "                'training_time': training_time,\n",
    "                'best_val_acc': training_stats['best_val_acc'],\n",
    "                'best_epoch': training_stats['best_epoch'],\n",
    "                'test_accuracy': eval_metrics['accuracy'],\n",
    "                'f1_score': eval_metrics['f1_score'],\n",
    "                'precision': eval_metrics['precision'],\n",
    "                'recall': eval_metrics['recall']\n",
    "            }\n",
    "            \n",
    "            # Add to results list\n",
    "            all_results.append(complete_results)\n",
    "            \n",
    "            # Optional: Save the model\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            save_dir = os.path.join(project_root, \"experiments\", \n",
    "                                   f\"{config['name'].lower().replace(' ', '_')}_{timestamp}\")\n",
    "            \n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "            save_path = os.path.join(save_dir, f\"{config['name'].lower().replace(' ', '_')}.pt\")\n",
    "            \n",
    "            save_model(\n",
    "                model,\n",
    "                config,\n",
    "                save_path,\n",
    "                metrics={\n",
    "                    'accuracy': eval_metrics['accuracy'],\n",
    "                    'f1_macro': eval_metrics['f1_score'],\n",
    "                    'best_val_acc': training_stats['best_val_acc'],\n",
    "                    'best_epoch': training_stats['best_epoch']\n",
    "                },\n",
    "                epoch=training_stats['best_epoch']\n",
    "            )\n",
    "            \n",
    "            print(f\"Model saved to {save_path}\")\n",
    "            \n",
    "            # Plot training history\n",
    "            plot_training_history(history)\n",
    "            \n",
    "            # Clear CUDA cache between models if using GPU\n",
    "            if torch.cuda.is_available():\n",
    "                del model\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error training {config['name']}: {e}\")\n",
    "            # Continue with next model on error\n",
    "            continue\n",
    "            \n",
    "    print(\"\\nAll models trained and evaluated with DataParallel!\")\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2dc51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Concurrent model training with memory management\n",
    "print(\"\\nSetting up concurrent training with threading\")\n",
    "\n",
    "# Function to train with ConcurrentTrainer\n",
    "def train_with_concurrent_trainer(max_concurrent=concurrent_models):\n",
    "    trainer = ConcurrentTrainer(\n",
    "        configs=model_configs,\n",
    "        dataloaders=dataloaders,\n",
    "        device=device,\n",
    "        max_concurrent=max_concurrent\n",
    "    )\n",
    "    \n",
    "    print(f\"Training {len(model_configs)} models with up to {max_concurrent} running concurrently\")\n",
    "    all_results = trainer.train_all_models()\n",
    "    print(\"\\nAll models trained and evaluated concurrently!\")\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93da4489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose which training approach to use\n",
    "USE_DATA_PARALLEL = False  # Option 1: Use DataParallel for each model sequentially\n",
    "USE_CONCURRENT = True      # Option 2: Train multiple models concurrently with threading\n",
    "USE_SEQUENTIAL = False     # Option 3: Original sequential approach\n",
    "\n",
    "# Will store all results in this list\n",
    "all_results = []\n",
    "\n",
    "if USE_DATA_PARALLEL:\n",
    "    print(\"\\nðŸš€ Using DataParallel approach for GPU utilization\")\n",
    "    all_results = train_with_data_parallel()\n",
    "elif USE_CONCURRENT and concurrent_models > 1:\n",
    "    print(f\"\\nðŸš€ Using concurrent training approach with {concurrent_models} models at once\")\n",
    "    all_results = train_with_concurrent_trainer(max_concurrent=concurrent_models)\n",
    "else:\n",
    "    print(\"\\nðŸš€ Using original sequential training approach\")\n",
    "    # Original sequential training code\n",
    "    for config in model_configs:\n",
    "        try:\n",
    "            # Train the model\n",
    "            results = train_model_with_config(config, dataloaders, device)\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            eval_metrics = evaluate_model_on_test(\n",
    "                results['model'],\n",
    "                test_loader,\n",
    "                device,\n",
    "                class_names,\n",
    "                model_name=config['name']\n",
    "            )\n",
    "            \n",
    "            # Combine results\n",
    "            complete_results = {\n",
    "                'model_name': config['name'],\n",
    "                'architecture': config['model']['architecture'],\n",
    "                'config': config,\n",
    "                'training_time': results['training_time'],\n",
    "                'best_val_acc': results['training_stats']['best_val_acc'],\n",
    "                'best_epoch': results['training_stats']['best_epoch'],\n",
    "                'test_accuracy': eval_metrics['accuracy'],\n",
    "                'f1_score': eval_metrics['f1_score'],\n",
    "                'precision': eval_metrics['precision'],\n",
    "                'recall': eval_metrics['recall']\n",
    "            }\n",
    "            \n",
    "            # Add to results list\n",
    "            all_results.append(complete_results)\n",
    "            \n",
    "            # Optional: Save the model\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            if IN_COLAB:\n",
    "                save_dir = os.path.join(project_root, \"experiments\", f\"{config['name'].lower().replace(' ', '_')}_{timestamp}\")\n",
    "            else:\n",
    "                save_dir = os.path.join(project_root, \"experiments\", f\"{config['name'].lower().replace(' ', '_')}_{timestamp}\")\n",
    "            \n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "            save_path = os.path.join(save_dir, f\"{config['name'].lower().replace(' ', '_')}.pt\")\n",
    "            \n",
    "            save_model(\n",
    "                results['model'],\n",
    "                config,\n",
    "                save_path,\n",
    "                metrics={\n",
    "                    'accuracy': eval_metrics['accuracy'],\n",
    "                    'f1_macro': eval_metrics['f1_score'],\n",
    "                    'best_val_acc': results['training_stats']['best_val_acc'],\n",
    "                    'best_epoch': results['training_stats']['best_epoch']\n",
    "                },\n",
    "                epoch=results['training_stats']['best_epoch']\n",
    "            )\n",
    "            \n",
    "            print(f\"Model saved to {save_path}\")\n",
    "            \n",
    "            # Clear CUDA cache between models if using GPU\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error training {config['name']}: {e}\")\n",
    "            # Continue with next model on error\n",
    "            continue\n",
    "    \n",
    "    print(\"\\nAll models trained and evaluated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630b0b73",
   "metadata": {},
   "source": [
    "## 7. Comparative Analysis of Models\n",
    "\n",
    "Now let's compare the performance of all the models:\n",
    "\n",
    "### GPU Parallelism\n",
    "\n",
    "In this section, we analyze how GPU parallelism impacts the performance of the models. By leveraging GPU parallelism, we can significantly reduce computation time and improve efficiency. This is particularly beneficial for large-scale datasets and complex models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd126f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from results for easier comparison\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Print comparison table\n",
    "print(\"\\nModel Comparison Results:\")\n",
    "comparison_table = results_df[['model_name', 'test_accuracy', 'f1_score', 'precision', 'recall', 'best_val_acc', 'training_time']]\n",
    "comparison_table['training_time_min'] = comparison_table['training_time'] / 60  # Convert to minutes\n",
    "comparison_table = comparison_table.drop('training_time', axis=1)\n",
    "comparison_table = comparison_table.sort_values('test_accuracy', ascending=False)\n",
    "print(comparison_table.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
    "\n",
    "# Create visualizations for comparison\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# 1. Test accuracy and F1 scores\n",
    "plt.subplot(2, 2, 1)\n",
    "models = comparison_table['model_name'].tolist()\n",
    "x = np.arange(len(models))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, comparison_table['test_accuracy'], width, label='Test Accuracy')\n",
    "plt.bar(x + width/2, comparison_table['f1_score'], width, label='F1 Score')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Test Accuracy and F1 Score Comparison')\n",
    "plt.xticks(x, models, rotation=45, ha='right')\n",
    "plt.ylim([0, 1.0])\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# 2. Training time\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.bar(models, comparison_table['training_time_min'], color='green')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Training Time (minutes)')\n",
    "plt.title('Training Time Comparison')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# 3. Precision and Recall\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.bar(x - width/2, comparison_table['precision'], width, label='Precision')\n",
    "plt.bar(x + width/2, comparison_table['recall'], width, label='Recall')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Precision and Recall Comparison')\n",
    "plt.xticks(x, models, rotation=45, ha='right')\n",
    "plt.ylim([0, 1.0])\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# 4. Best Validation Accuracy\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.bar(models, comparison_table['best_val_acc'], color='purple')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Best Validation Accuracy')\n",
    "plt.title('Best Validation Accuracy Comparison')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylim([0, 1.0])\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(project_root, 'results', 'model_comparison.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Identify the best model\n",
    "best_model_name = comparison_table.iloc[0]['model_name']\n",
    "best_model_accuracy = comparison_table.iloc[0]['test_accuracy']\n",
    "print(f\"\\nBest Model: {best_model_name} with Test Accuracy: {best_model_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897f607e",
   "metadata": {},
   "source": [
    "## 8. Conclusion and Next Steps\n",
    "\n",
    "We've now compared several CustomCNN architectures using our flexible framework. Based on the results, we can see which architecture performs best for our musical instrument classification task.\n",
    "\n",
    "### Analysis\n",
    "\n",
    "Let's analyze what we've learned from this comparison:\n",
    "\n",
    "1. **Performance across architectures**: We can see that different architectures have different strengths and weaknesses. The best-performing model likely achieves a balance between model capacity and regularization.\n",
    "\n",
    "2. **Training Efficiency**: The training time varies significantly across models. Models with more parameters (like Wider CNN) or deeper architectures typically take longer to train.\n",
    "\n",
    "3. **Regularization Impact**: The regularized variant shows how adding dropout and weight decay affects the model's performance, potentially improving generalization on test data.\n",
    "\n",
    "4. **ResNet18 Comparison**: The ResNet18 model provides a strong baseline against which we can compare our custom architectures.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Optimize the best architecture**: Now that we've identified the best-performing CustomCNN architecture, we can further optimize it by:\n",
    "   - Fine-tuning hyperparameters\n",
    "   - Applying more advanced regularization techniques\n",
    "   - Experimenting with different learning rate schedules\n",
    "\n",
    "2. **Test on more challenging data**: To ensure our model is robust, we could test it on more challenging data or in real-world scenarios.\n",
    "\n",
    "3. **Model Ensemble**: We could also explore ensemble methods by combining predictions from multiple models to further improve performance.\n",
    "\n",
    "4. **Model Simplification**: If the best model is complex, we could explore model simplification techniques like pruning or distillation to make it more deployable.\n",
    "\n",
    "In the next notebook, we'll take the best architecture identified here and further optimize it to create our final model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09295cd8",
   "metadata": {},
   "source": [
    "## 9. Prepare for Step 2: Optimized CustomCNN\n",
    "\n",
    "Based on our model comparison, we'll now prepare for Step 2 using the optimized CustomCNN configuration. We'll load the configuration from the YAML file and make it ready for the next phase of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee05ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the optimized CustomCNN configuration\n",
    "try:\n",
    "    # Build the path to the config file\n",
    "    optimized_config_path = os.path.join(project_root, \"config\", \"optimized_custom_cnn.yaml\")\n",
    "    \n",
    "    # Load the configuration\n",
    "    with open(optimized_config_path, \"r\") as f:\n",
    "        optimized_config = yaml.safe_load(f)\n",
    "    \n",
    "    print(f\"Loaded optimized CustomCNN configuration from {optimized_config_path}\")\n",
    "    print(\"\\nOptimized CustomCNN configuration:\")\n",
    "    print(f\"Architecture: {optimized_config['model']['name']}\")\n",
    "    \n",
    "    # Display some key parameters\n",
    "    print(\"\\nKey parameters:\")\n",
    "    print(f\"- Dropout rate: {optimized_config['model']['dropout_rate']}\")\n",
    "    print(f\"- Optimizer: {optimized_config['training']['optimizer']['name']}\")\n",
    "    print(f\"- Learning rate: {optimized_config['training']['optimizer']['learning_rate']}\")\n",
    "    print(f\"- Weight decay: {optimized_config['training']['optimizer']['weight_decay']}\")\n",
    "    print(f\"- Scheduler: {optimized_config['training']['scheduler']['name']}\")\n",
    "    print(f\"- Augmentation strength: {optimized_config['augmentation']['augmentation_strength']}\")\n",
    "    \n",
    "    print(\"\\nThis optimized configuration will be used in Step 2\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading optimized configuration: {e}\")\n",
    "    print(\"You'll need to create or modify the optimized_custom_cnn.yaml file for Step 2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
