{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dfe4cba",
   "metadata": {},
   "source": [
    "# Custom CNN Model Optimization\n",
    "\n",
    "This notebook focuses on optimizing the custom CNN model for musical instrument classification using the flexible framework. We'll explore various optimization techniques and evaluate their impact on performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8928d503",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Let's set up the environment by importing the necessary libraries and modules from our project structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e08449e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Add the project root to the path to enable importing from our package\n",
    "project_root = Path(os.getcwd()).parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "    \n",
    "# Import from our project modules\n",
    "from src.data.dataset import InstrumentDataset, get_transforms\n",
    "from src.data.preprocessing import create_train_val_split\n",
    "from src.models.custom_cnn import MusicInstrumentCNN, create_custom_cnn\n",
    "from src.training.trainer import train_model, evaluate_model\n",
    "from src.training.scheduler import get_scheduler\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Function to load configuration\n",
    "def load_config(config_path):\n",
    "    with open(config_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44a4843",
   "metadata": {},
   "source": [
    "## Load the Optimized Configuration\n",
    "\n",
    "We'll use our new optimized configuration to guide the model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9299e411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration from YAML file\n",
    "config_path = project_root / \"config\" / \"optimized_custom_cnn.yaml\"\n",
    "config = load_config(config_path)\n",
    "\n",
    "# Display the configuration\n",
    "print(\"Model Configuration:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70182503",
   "metadata": {},
   "source": [
    "## Data Preparation with Enhanced Augmentation\n",
    "\n",
    "We'll implement stronger data augmentation strategies to improve model generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85720e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "def get_enhanced_transforms(img_size=224, augmentation_strength='strong'):\n",
    "    \"\"\"\n",
    "    Get enhanced data transforms for training and validation\n",
    "    \n",
    "    Args:\n",
    "        img_size (int): Image size for resizing\n",
    "        augmentation_strength (str): Strength of augmentations ('light', 'medium', 'strong')\n",
    "        \n",
    "    Returns:\n",
    "        train_transform: Transforms for training data\n",
    "        val_transform: Transforms for validation data\n",
    "    \"\"\"\n",
    "    # Basic validation transform (resize and normalize)\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Define augmentation parameters based on strength\n",
    "    if augmentation_strength == 'light':\n",
    "        color_jitter = transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05)\n",
    "        erasing_prob = 0.1\n",
    "        rotation_degrees = 10\n",
    "    elif augmentation_strength == 'medium':\n",
    "        color_jitter = transforms.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.15, hue=0.1)\n",
    "        erasing_prob = 0.2\n",
    "        rotation_degrees = 15\n",
    "    else:  # strong\n",
    "        color_jitter = transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n",
    "        erasing_prob = 0.3\n",
    "        rotation_degrees = 20\n",
    "    \n",
    "    # Enhanced training transform\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(img_size, scale=(0.8, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(rotation_degrees),\n",
    "        color_jitter,\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        transforms.RandomErasing(p=erasing_prob)\n",
    "    ])\n",
    "    \n",
    "    return train_transform, val_transform\n",
    "\n",
    "# Set paths\n",
    "data_dir = project_root / \"data\" / \"raw\" / \"30_Musical_Instruments\"\n",
    "\n",
    "# Create train/validation split\n",
    "train_files, val_files, classes = create_train_val_split(\n",
    "    data_dir, \n",
    "    val_split=0.2,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"Number of classes: {len(classes)}\")\n",
    "print(f\"Number of training samples: {len(train_files)}\")\n",
    "print(f\"Number of validation samples: {len(val_files)}\")\n",
    "\n",
    "# Get enhanced data transforms\n",
    "augmentation_strength = config.get('augmentation', {}).get('augmentation_strength', 'strong')\n",
    "img_size = config.get('data', {}).get('img_size', 224)\n",
    "train_transform, val_transform = get_enhanced_transforms(\n",
    "    img_size=img_size,\n",
    "    augmentation_strength=augmentation_strength\n",
    ")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = InstrumentDataset(train_files, classes, transform=train_transform)\n",
    "val_dataset = InstrumentDataset(val_files, classes, transform=val_transform)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = config.get('training', {}).get('batch_size', 32)\n",
    "num_workers = config.get('data', {}).get('num_workers', 4)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b155e378",
   "metadata": {},
   "source": [
    "## Visualize Augmented Images\n",
    "\n",
    "Let's visualize some examples of our augmented training images to make sure our augmentation strategy is effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d81a657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_augmentations(dataset, num_samples=8, num_augmentations=5):\n",
    "    \"\"\"\n",
    "    Visualize the effect of data augmentations on samples from the dataset\n",
    "    \n",
    "    Args:\n",
    "        dataset: The dataset with augmentations applied\n",
    "        num_samples: Number of different samples to visualize\n",
    "        num_augmentations: Number of augmentations to apply to each sample\n",
    "    \"\"\"\n",
    "    # Get random indices from the dataset\n",
    "    indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
    "    \n",
    "    plt.figure(figsize=(num_augmentations * 3, num_samples * 3))\n",
    "    denormalize = transforms.Compose([\n",
    "        transforms.Normalize(mean=[0, 0, 0], std=[1/0.229, 1/0.224, 1/0.225]),\n",
    "        transforms.Normalize(mean=[-0.485, -0.456, -0.406], std=[1, 1, 1]),\n",
    "    ])\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        original_sample = dataset.get_original(idx)\n",
    "        plt.subplot(num_samples, num_augmentations + 1, i * (num_augmentations + 1) + 1)\n",
    "        plt.imshow(original_sample)\n",
    "        plt.title(f\"Original\\n{classes[dataset.labels[idx]]}\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        for j in range(num_augmentations):\n",
    "            # Apply augmentation\n",
    "            img, _ = dataset[idx]\n",
    "            # Denormalize for visualization\n",
    "            img = denormalize(img)\n",
    "            img = torch.clamp(img, 0, 1)\n",
    "            img = img.permute(1, 2, 0).numpy()\n",
    "            \n",
    "            plt.subplot(num_samples, num_augmentations + 1, i * (num_augmentations + 1) + j + 2)\n",
    "            plt.imshow(img)\n",
    "            plt.title(f\"Augmentation {j+1}\")\n",
    "            plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Add a method to the InstrumentDataset class to get original (non-augmented) images\n",
    "def get_original(self, idx):\n",
    "    \"\"\"\n",
    "    Get the original image without any transformations\n",
    "    \n",
    "    Args:\n",
    "        idx (int): Index of the image\n",
    "        \n",
    "    Returns:\n",
    "        PIL.Image: The original image\n",
    "    \"\"\"\n",
    "    img_path = self.image_paths[idx]\n",
    "    return Image.open(img_path).convert('RGB')\n",
    "\n",
    "# Attach the method to the class\n",
    "from PIL import Image\n",
    "InstrumentDataset.get_original = get_original\n",
    "\n",
    "# Visualize the augmentations\n",
    "visualize_augmentations(train_dataset, num_samples=4, num_augmentations=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db4b60e",
   "metadata": {},
   "source": [
    "## Initialize the Optimized Model\n",
    "\n",
    "Let's set up our custom CNN model with the optimized parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266aac5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = create_custom_cnn(\n",
    "    num_classes=len(classes), \n",
    "    input_channels=3\n",
    ")\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Print model architecture and parameter count\n",
    "print(model)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f9f7a6",
   "metadata": {},
   "source": [
    "## Enhanced Training Configuration\n",
    "\n",
    "Now, we'll set up our training with optimized hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd2a992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Get optimizer parameters from config\n",
    "optimizer_config = config.get('training', {}).get('optimizer', {})\n",
    "optimizer_name = optimizer_config.get('name', 'adamw').lower()\n",
    "lr = optimizer_config.get('learning_rate', 0.001)\n",
    "weight_decay = optimizer_config.get('weight_decay', 0.001)\n",
    "beta1 = optimizer_config.get('beta1', 0.9)\n",
    "beta2 = optimizer_config.get('beta2', 0.999)\n",
    "\n",
    "# Create optimizer\n",
    "if optimizer_name == 'adam':\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(), \n",
    "        lr=lr,\n",
    "        weight_decay=weight_decay,\n",
    "        betas=(beta1, beta2)\n",
    "    )\n",
    "elif optimizer_name == 'adamw':\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(), \n",
    "        lr=lr,\n",
    "        weight_decay=weight_decay,\n",
    "        betas=(beta1, beta2)\n",
    "    )\n",
    "elif optimizer_name == 'sgd':\n",
    "    momentum = optimizer_config.get('momentum', 0.9)\n",
    "    nesterov = optimizer_config.get('nesterov', True)\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(), \n",
    "        lr=lr,\n",
    "        momentum=momentum,\n",
    "        weight_decay=weight_decay,\n",
    "        nesterov=nesterov\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported optimizer: {optimizer_name}\")\n",
    "\n",
    "# Get scheduler parameters from config\n",
    "scheduler_config = config.get('training', {}).get('scheduler', {})\n",
    "scheduler_name = scheduler_config.get('name', 'onecycle').lower()\n",
    "num_epochs = config.get('training', {}).get('num_epochs', 75)\n",
    "\n",
    "# Create scheduler\n",
    "if scheduler_name == 'onecycle':\n",
    "    max_lr = scheduler_config.get('max_lr', 0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=max_lr,\n",
    "        steps_per_epoch=len(train_loader),\n",
    "        epochs=num_epochs,\n",
    "        pct_start=scheduler_config.get('pct_start', 0.3),\n",
    "        div_factor=25.0,  # initial_lr = max_lr / div_factor\n",
    "        final_div_factor=10000.0  # final_lr = initial_lr / final_div_factor\n",
    "    )\n",
    "elif scheduler_name == 'cosine':\n",
    "    t_max = scheduler_config.get('t_max', num_epochs)\n",
    "    eta_min = scheduler_config.get('eta_min', 0.000001)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer,\n",
    "        T_max=t_max,\n",
    "        eta_min=eta_min\n",
    "    )\n",
    "elif scheduler_name == 'step':\n",
    "    step_size = scheduler_config.get('step_size', 30)\n",
    "    gamma = scheduler_config.get('gamma', 0.1)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "        optimizer,\n",
    "        step_size=step_size,\n",
    "        gamma=gamma\n",
    "    )\n",
    "elif scheduler_name == 'plateau':\n",
    "    patience = scheduler_config.get('patience', 5)\n",
    "    factor = scheduler_config.get('factor', 0.1)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='min',\n",
    "        factor=factor,\n",
    "        patience=patience,\n",
    "        min_lr=1e-6\n",
    "    )\n",
    "else:\n",
    "    scheduler = None\n",
    "\n",
    "# Print training configuration\n",
    "print(f\"Training for {num_epochs} epochs\")\n",
    "print(f\"Optimizer: {optimizer_name}\")\n",
    "print(f\"Learning rate: {lr}\")\n",
    "print(f\"Weight decay: {weight_decay}\")\n",
    "print(f\"Scheduler: {scheduler_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759770ce",
   "metadata": {},
   "source": [
    "## Implement Gradient Clipping\n",
    "\n",
    "Gradient clipping helps stabilize training by preventing exploding gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52674480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified training function with gradient clipping\n",
    "def train_model_with_clipping(model, dataloaders, criterion, optimizer, device, \n",
    "                            scheduler=None, num_epochs=10, gradient_clip_val=1.0, verbose=True):\n",
    "    \"\"\"\n",
    "    Enhanced training function with gradient clipping\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): PyTorch model to train\n",
    "        dataloaders (dict): Dictionary of PyTorch DataLoader objects for 'train' and 'val'\n",
    "        criterion: Loss function\n",
    "        optimizer: Optimizer to use\n",
    "        device (torch.device): Device to train on (GPU or CPU)\n",
    "        scheduler: Learning rate scheduler (optional)\n",
    "        num_epochs (int): Number of epochs to train for\n",
    "        gradient_clip_val (float): Max norm for gradient clipping\n",
    "        verbose (bool): Whether to print progress\n",
    "        \n",
    "    Returns:\n",
    "        model: Best model based on validation accuracy\n",
    "        history (dict): Training and validation metrics\n",
    "        training_stats (dict): Training statistics\n",
    "    \"\"\"\n",
    "    since = time.time()\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'lr': []}\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    \n",
    "    # Early stopping parameters\n",
    "    patience = config.get('regularization', {}).get('early_stopping', {}).get('patience', 15)\n",
    "    min_delta = config.get('regularization', {}).get('early_stopping', {}).get('min_delta', 0.001)\n",
    "    counter = 0\n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    import copy\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        if verbose:\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "            print('-' * 10)\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            # Progress bar for the dataloader\n",
    "            dataloader = dataloaders[phase]\n",
    "            progress_bar = tqdm(dataloader, desc=f'{phase} Epoch {epoch+1}/{num_epochs}') if verbose else dataloader\n",
    "            \n",
    "            # Iterate over data (batch)\n",
    "            for inputs, labels in progress_bar:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Forward pass - track history only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    # Backward pass + optimize only in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        \n",
    "                        # Gradient clipping\n",
    "                        torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clip_val)\n",
    "                        \n",
    "                        optimizer.step()\n",
    "                        \n",
    "                        # Step OneCycleLR per iteration\n",
    "                        if isinstance(scheduler, torch.optim.lr_scheduler.OneCycleLR):\n",
    "                            scheduler.step()\n",
    "                \n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                # Update progress bar if using tqdm\n",
    "                if verbose:\n",
    "                    progress_bar.set_postfix({\n",
    "                        'loss': loss.item(), \n",
    "                        'accuracy': torch.sum(preds == labels.data).item() / inputs.size(0)\n",
    "                    })\n",
    "            \n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            \n",
    "            # Store the metrics\n",
    "            if phase == 'train':\n",
    "                history['train_loss'].append(epoch_loss)\n",
    "                history['train_acc'].append(epoch_acc.item())\n",
    "                history['lr'].append(optimizer.param_groups[0]['lr'])\n",
    "            else:\n",
    "                history['val_loss'].append(epoch_loss)\n",
    "                history['val_acc'].append(epoch_acc.item())\n",
    "            \n",
    "            if verbose:\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "            \n",
    "            # LR Scheduler step if it's a validation phase and not OneCycleLR\n",
    "            if phase == 'val':\n",
    "                if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                    scheduler.step(epoch_loss)\n",
    "                elif scheduler and not isinstance(scheduler, torch.optim.lr_scheduler.OneCycleLR):\n",
    "                    scheduler.step()\n",
    "                \n",
    "                # Early stopping check\n",
    "                if epoch_loss < best_loss - min_delta:\n",
    "                    best_loss = epoch_loss\n",
    "                    counter = 0\n",
    "                else:\n",
    "                    counter += 1\n",
    "                    if verbose and counter > 0:\n",
    "                        print(f\"Early stopping counter: {counter}/{patience}\")\n",
    "                    \n",
    "                    if counter >= patience:\n",
    "                        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                        # Load the best model weights\n",
    "                        model.load_state_dict(best_model_wts)\n",
    "                        \n",
    "                        # Calculate and print training time\n",
    "                        time_elapsed = time.time() - since\n",
    "                        if verbose:\n",
    "                            print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "                            print(f'Best val Acc: {best_acc:.4f} at epoch {best_epoch}')\n",
    "                        \n",
    "                        # Store training statistics\n",
    "                        training_stats = {\n",
    "                            'training_time': f\"{time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s\",\n",
    "                            'best_val_acc': best_acc.item(),\n",
    "                            'best_epoch': best_epoch,\n",
    "                            'stopped_early': True,\n",
    "                            'stopped_epoch': epoch + 1\n",
    "                        }\n",
    "                        \n",
    "                        return model, history, training_stats\n",
    "            \n",
    "            # Save the best model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_epoch = epoch + 1\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                if verbose:\n",
    "                    print(f'New best model found! Val accuracy: {best_acc:.4f}')\n",
    "        \n",
    "        if verbose:\n",
    "            print()\n",
    "    \n",
    "    # Calculate and print training time\n",
    "    time_elapsed = time.time() - since\n",
    "    if verbose:\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:.4f} at epoch {best_epoch}')\n",
    "    \n",
    "    # Store training statistics\n",
    "    training_stats = {\n",
    "        'training_time': f\"{time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s\",\n",
    "        'best_val_acc': best_acc.item(),\n",
    "        'best_epoch': best_epoch,\n",
    "        'stopped_early': False\n",
    "    }\n",
    "    \n",
    "    # Load the best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, history, training_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971aa1df",
   "metadata": {},
   "source": [
    "## Train the Optimized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59b1e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders dictionary\n",
    "dataloaders = {\n",
    "    'train': train_loader,\n",
    "    'val': val_loader\n",
    "}\n",
    "\n",
    "# Gradient clipping value\n",
    "gradient_clip_val = config.get('regularization', {}).get('gradient_clipping', {}).get('max_norm', 1.0)\n",
    "\n",
    "# Train the model\n",
    "print(f\"Starting model training for {num_epochs} epochs...\")\n",
    "optimized_model, history, training_stats = train_model_with_clipping(\n",
    "    model=model,\n",
    "    dataloaders=dataloaders,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    device=device,\n",
    "    num_epochs=num_epochs,\n",
    "    gradient_clip_val=gradient_clip_val,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Print training summary\n",
    "print(\"\\nTraining summary:\")\n",
    "print(f\"Best validation accuracy: {training_stats['best_val_acc']:.4f} at epoch {training_stats['best_epoch']}\")\n",
    "print(f\"Training time: {training_stats['training_time']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8efcf58",
   "metadata": {},
   "source": [
    "## Visualize Training Metrics\n",
    "\n",
    "Let's plot the learning curves to understand the training dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df560ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"Plot the training and validation metrics\"\"\"\n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    \n",
    "    # Create a 2x2 grid of plots\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    \n",
    "    # Plot training & validation loss\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(epochs, history['train_loss'], 'b-', label='Training Loss')\n",
    "    plt.plot(epochs, history['val_loss'], 'r-', label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot training & validation accuracy\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(epochs, history['train_acc'], 'b-', label='Training Accuracy')\n",
    "    plt.plot(epochs, history['val_acc'], 'r-', label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot learning rate\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(epochs, history['lr'], 'g-')\n",
    "    plt.title('Learning Rate')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Learning Rate')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot validation accuracy vs. learning rate\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.scatter(history['lr'], history['val_acc'], alpha=0.7)\n",
    "    plt.title('Validation Accuracy vs. Learning Rate')\n",
    "    plt.xlabel('Learning Rate')\n",
    "    plt.ylabel('Validation Accuracy')\n",
    "    plt.xscale('log')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the training history\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22eb50eb",
   "metadata": {},
   "source": [
    "## Evaluate on Test Set\n",
    "\n",
    "Let's evaluate our optimized model on the test set to see if our optimizations improved performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693028d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test dataset and loader\n",
    "test_files, _, _ = create_train_val_split(\n",
    "    data_dir, \n",
    "    val_split=0.0,  # Don't create a validation set\n",
    "    test_split=0.2,  # Use 20% of data for testing\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"Number of test samples: {len(test_files)}\")\n",
    "\n",
    "test_dataset = InstrumentDataset(test_files, classes, transform=val_transform)  # Use validation transform for testing\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "print(\"Evaluating model on test set...\")\n",
    "test_accuracy, all_preds, all_labels = evaluate_model(\n",
    "    model=optimized_model,\n",
    "    test_loader=test_loader,\n",
    "    device=device,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"Test Results:\")\n",
    "print(f\"- Accuracy: {test_accuracy/100:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d204736c",
   "metadata": {},
   "source": [
    "## Confusion Matrix and Detailed Analysis\n",
    "\n",
    "Let's create a confusion matrix and classification report to better understand our model's strengths and weaknesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bb7877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(20, 16))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(all_labels, all_preds, target_names=classes)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04209990",
   "metadata": {},
   "source": [
    "## Save the Optimized Model\n",
    "\n",
    "Let's save our optimized model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3938e29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory to save the model\n",
    "save_dir = project_root / \"experiments\" / \"optimized_custom_cnn\"\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save model weights\n",
    "model_save_path = save_dir / \"optimized_model.pth\"\n",
    "torch.save(optimized_model.state_dict(), model_save_path)\n",
    "\n",
    "# Save training history and statistics\n",
    "import json\n",
    "history_save_path = save_dir / \"training_history.json\"\n",
    "with open(history_save_path, 'w') as f:\n",
    "    json.dump({\n",
    "        'train_loss': [float(x) for x in history['train_loss']],\n",
    "        'train_acc': [float(x) for x in history['train_acc']],\n",
    "        'val_loss': [float(x) for x in history['val_loss']],\n",
    "        'val_acc': [float(x) for x in history['val_acc']],\n",
    "        'lr': [float(x) for x in history['lr']],\n",
    "    }, f)\n",
    "\n",
    "stats_save_path = save_dir / \"training_stats.json\"\n",
    "with open(stats_save_path, 'w') as f:\n",
    "    # Convert any tensor values to float\n",
    "    stats_dict = {}\n",
    "    for k, v in training_stats.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            stats_dict[k] = v.item()\n",
    "        else:\n",
    "            stats_dict[k] = v\n",
    "    json.dump(stats_dict, f)\n",
    "\n",
    "print(f\"Model saved to {model_save_path}\")\n",
    "print(f\"Training history saved to {history_save_path}\")\n",
    "print(f\"Training statistics saved to {stats_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3005df4f",
   "metadata": {},
   "source": [
    "## Compare with Baseline Results\n",
    "\n",
    "Let's compare our optimized model with the previous baseline custom model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26e750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance comparison\n",
    "comparison_data = {\n",
    "    'Model': ['ResNet-18 (Transfer Learning)', 'Original Custom CNN', 'Optimized Custom CNN'],\n",
    "    'Test Accuracy': ['100.00%', '80.67%', f'{test_accuracy:.2f}%'],\n",
    "    'Training Time': ['11m 20s', '28m 47s', training_stats['training_time']],\n",
    "    'Best Epoch': [8, 47, training_stats['best_epoch']],\n",
    "    'Parameters': ['11.7 million', '8.6 million', f'{trainable_params/1e6:.1f} million']\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"Model Performance Comparison:\")\n",
    "display(comparison_df)\n",
    "\n",
    "# Create a summary of optimization changes\n",
    "optimization_summary = \"\"\"\n",
    "## Key Optimizations Applied:\n",
    "\n",
    "1. **Enhanced Data Augmentation**:\n",
    "   - Increased augmentation strength to improve model generalization\n",
    "   - Added random erasing and more advanced transformations\n",
    "\n",
    "2. **Optimizer Improvements**:\n",
    "   - Switched from Adam to AdamW for better weight decay handling\n",
    "   - Increased weight decay for better regularization\n",
    "\n",
    "3. **Learning Rate Scheduling**:\n",
    "   - Implemented OneCycleLR policy for faster convergence\n",
    "   - Used warmup period to stabilize early training\n",
    "\n",
    "4. **Regularization Techniques**:\n",
    "   - Applied gradient clipping to prevent exploding gradients\n",
    "   - Implemented early stopping to prevent overfitting\n",
    "   - Adjusted dropout rates for better feature learning\n",
    "\n",
    "5. **Training Process Improvements**:\n",
    "   - Increased number of epochs to allow for more learning\n",
    "   - Maintained batch size for stable training\n",
    "   - Added extensive monitoring of training metrics\n",
    "\"\"\"\n",
    "\n",
    "print(optimization_summary)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
