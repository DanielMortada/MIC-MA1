% =====================================
% Introduction Section
% File: sections/introduction.tex
% =====================================

\section{Introduction}
\noindent
Classifying musical instruments from images is a challenging computer‑vision task with applications in music education, content retrieval, and multimedia indexing. Accurate recognition demands models that capture subtle variations in shape, texture, and context. Convolutional neural networks (CNNs) \cite{krizhevsky2012imagenet, simonyan2014very} address this need through automatic feature extraction and hierarchical pattern learning.

\noindent
We investigate this problem in three phases. Phase~1 contrasts transfer learning with a ResNet‑18 baseline (99.33\% test accuracy) against a custom CNN trained from scratch (80.67\%). Phase~2 evaluates custom variants in a unified framework, showing that increased depth yields the best custom model (Deeper CNN, 86.67\%). Phase~3 refines that model: an initial optimization regressed to 81.00\%, but failure‑driven adjustments – class‑specific augmentation, selective attention, balanced regularization, and mixed‑precision training – raised accuracy to 93.33\% and cut the gap to the baseline to 6.00\%.

\noindent
The study contributes:  
(1) a head‑to‑head assessment of transfer learning versus bespoke architectures for 30‑class instrument recognition;  
(2) a controlled comparison revealing depth as a key design lever and highlighting regularization pitfalls;  
(3) evidence that systematic failure analysis and targeted optimizations can push custom CNNs close to transfer‑learning performance.

\noindent
The rest of the paper is organized as follows. Section~II details the dataset and experimental setup. Section~III describes the methodology. Section~IV reports results and analysis. Section~V concludes and outlines future work.
