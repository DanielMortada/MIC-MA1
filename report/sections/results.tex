% =====================================
% Results and Discussion Section
% File: sections/results.tex
% =====================================

\section{Results and Discussion}

\subsection{Phase~1 - ResNet\textendash18 vs. Custom CNN}

\noindent
\textbf{Baseline.} ResNet\textendash18 achieved 100\% test accuracy after eight fine\hyp tuning epochs with a total training time of 11~min~20~s (Figure \autoref{fig:curve_resnet18}).\\
\textbf{Custom.} The scratch trained CNN attained 80.67\% accuracy over 29~minutes of training, with validation accuracy peaking at 83.33\% by epoch~47 (Figure \autoref{fig:curve_customcnn}).



\begin{figure}[htbp]
    \centering
    \subfloat[ResNet-18 learning curve]{%
        \includegraphics[width=\columnwidth]{figures/learning_curve_ResNet18.png}%
        \label{fig:curve_resnet18}
    }\\[1ex]
    \subfloat[Custom CNN learning curve]{%
        \includegraphics[width=\columnwidth]{figures/learning_curve_CustomCNN.png}%
        \label{fig:curve_customcnn}
    }
    \caption{Learning curves for ResNet-18 and Custom CNN during Phase~1. Each plot shows training and validation accuracy over epochs, highlighting ResNet-18's faster convergence (8 epochs) versus the custom model (47 epochs). Transfer learning shows advantages in both convergence speed and final performance.}
    \label{fig:learning_curves_phase1}
\end{figure}



\noindent
Table~\ref{tab:phase1} presents a quantitative comparison between the two approaches. ResNet\textendash18 demonstrates 4× faster training time and 19.33~percentage point higher accuracy, despite requiring 3.1~million additional parameters. The custom model exhibits reasonable generalization capability considering its comparatively limited parameter count.
\begin{table}[h!]
\caption{\small Comparison of Phase~1 Models}
\label{tab:phase1}
\centering
\begin{tabular}{lcccc}
\toprule
Model & Parameters & Test Acc. & Training Time & Best Epoch \\
\midrule
ResNet\textendash18 & 11.7M & 99.33\% & 11m 20s & 8 \\
Custom CNN & 8.6M & 80.67\% & 29m & 47 \\
\bottomrule
\end{tabular}
\end{table}

% TODO: learning‑curve figure

\subsection{Phase~2 - Architecture Survey}

\noindent
Table~\ref{tab:variants} summarizes performance metrics for five CNN architecture variants evaluated under identical training protocols.\\

\begin{table}[htbp]
\caption{\small Performance of CNN Variants}
\label{tab:variants}
\centering
\begin{tabular}{lcccc}
\toprule
Model & Test Acc. & F1 & Recall & Time (min) \\
\midrule
ResNet\textendash18 & 99.33\% & 0.993 & 0.993 & 32.5 \\
Deeper CNN & 86.67\% & 0.857 & 0.867 & 36.1 \\
Base CNN & 85.33\% & 0.845 & 0.853 & 35.0 \\
Regularised CNN & 81.33\% & 0.803 & 0.813 & 38.4 \\
Wider CNN & 80.67\% & 0.797 & 0.807 & 62.3 \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\linewidth]{figures/phase2_res_comparison.png}
    \caption{\small Comparative performance metrics across CNN architectures evaluated in Phase~2. The subplots present (a) test accuracy and F1-score, (b) training time, (c) precision and recall, and (d) best validation accuracy for ResNet-18, Deeper CNN, Base CNN, Regularized CNN, and Wider CNN models.}
    \label{fig:phase2_results}
\end{figure}


\noindent
The experimental results (\autoref{fig:phase2_results}) indicate that architectural depth contributes more significantly to classification performance than increased width. Conversely, excessive regularization demonstrates a detrimental effect on accuracy. Based on these findings, the Deeper CNN architecture was selected for further optimization in Phase~3 (\autoref{fig:learning_curve_deepercnn}).

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\linewidth]{figures/learning_curve_DeepeCNN.png}
    \caption{\small Training and validation learning curves for the Deeper CNN model over 50 epochs. The plots show (a) loss and (b) accuracy across epochs, highlighting consistent convergence and generalization. Validation accuracy surpasses training accuracy throughout, indicating effective regularization without signs of overfitting.}
    \label{fig:learning_curve_deepercnn}
\end{figure}

\newpage
\subsection{Phase~3 - Deeper CNN Optimisation}

\noindent
\textbf{Phase~3.1.} Implementation of residual connections, progressive dropout (0.1‑0.5), and AdamW with weight decay of 0.001 resulted in accuracy regression to 81\%. Continuous decline in both training and validation losses throughout 75 epochs, coupled with a substantial training‑validation accuracy gap (61\% vs. 87\%), indicated under‑fitting rather than over‑fitting.

\textbf{Phase~3.2.} Systematic failure analysis informed refinements: class‑specific augmentation for challenging instruments, calibrated dropout progression (0.05‑0.3), selective attention mechanisms in deeper layers (4‑6), and reduced weight decay (0.0005). The model efficiently converged at epoch 55 of the maximum 100 epochs, with peak validation accuracy of 96.67\%. These adjustments elevated accuracy to 93.33\%; Table~\ref{tab:opt} quantifies the progression.

\begin{table}[ht]
\caption{\small Deeper CNN Optimisation Progression}
\label{tab:opt}
\centering
\begin{tabular}{lccc}
\toprule
Model Variant & Test Acc. & Val. Acc. & Params (M) \\
\midrule
Original Deeper CNN & 86.67\% & 90.67\% & 9.2 \\
Phase~3.1 Optimisation & 81.00\% & 87.33\% & 13.6 \\
\textbf{Phase~3.2 Optimisation} & \textbf{93.33\%} & \textbf{96.67\%} & 15.0 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Class-Level Effects}

\noindent
Targeted augmentation significantly improved classification performance for previously challenging instruments: Didgeridoo F1‑score increased from 33\% to 75\%, Trombone from 60\% to 100\%, and Sitar from 62\% to 89\%. Two instruments—Flute and Alphorn—remained difficult to classify accurately (F1‑scores of 60\% and 57\% respectively) due to their similar cylindrical profiles and limited distinctive visual features.

\subsection{Discussion}

\noindent
While ResNet\textendash18 remains superior in overall performance, the refined custom architecture with failure‑driven optimization reduced the accuracy gap to 6~percentage points. The experimental results demonstrate three significant principles:
\begin{itemize}
    \item Network depth contributes more effectively to classification performance than width for the musical instrument recognition task.
    \item Concurrent application of multiple regularization techniques can create adverse interactions that degrade learning capacity rather than enhancing generalization.
    \item Class‑specific augmentation combined with selective attention mechanisms provides substantial performance improvements for fine‑grained visual classification tasks.
\end{itemize}

\noindent
The iterative optimization approach demonstrates that systematic analysis of failure cases often yields more valuable insights than immediate success. The 12.33\% accuracy improvement from Phase~3.1 to Phase~3.2 illustrates how negative results, when properly analyzed, can guide effective architectural and training refinements.
