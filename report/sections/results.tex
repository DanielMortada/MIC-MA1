% =====================================
% Results and Discussion Section
% File: sections/results.tex
% =====================================

\section{Results and Discussion}
This section presents the empirical findings derived from our three-phase investigation, detailing the performance of the baseline model, the comparative analysis of custom CNN architectures, and the outcomes of the final optimization phase.

\subsection{Phase 1 Results: ResNet-18 vs. Initial Custom CNN}

\subsubsection{Baseline ResNet-18 Performance}
The ResNet-18 model, leveraging transfer learning, exhibited exceptional performance on the musical instrument classification task. It achieved a test accuracy of 100\% after only 8 epochs of fine-tuning, requiring approximately 11 minutes and 20 seconds. This rapid convergence underscores the effectiveness of its pre-trained ImageNet features, which proved highly transferable and required minimal adaptation for this specific domain.

\subsubsection{Initial Custom CNN Performance}
In contrast, our custom CNN architecture, trained entirely from scratch, attained a test accuracy of 80.67\%. While numerically lower than the baseline, this result is nonetheless commendable, considering the model learned all relevant features autonomously from the provided dataset. The training process spanned approximately 29 minutes, with the model reaching its peak validation accuracy of 83.33\% at epoch 47.

The learning trajectory demonstrated steady progress:
\begin{itemize}
    \item During early training (Epochs 1-10), validation accuracy increased rapidly from 5.33\% to 34.67\%.
    \item Through mid-training (Epochs 11-30), learning continued steadily, reaching 66.00\% validation accuracy.
    \item In late training (Epochs 31-47), the model refined its feature representations, culminating in the peak validation accuracy.
\end{itemize}
The relatively narrow gap between the peak validation accuracy (83.33\%) and the final test accuracy (80.67\%) suggests reasonable generalization capabilities without evidence of significant overfitting.

% TODO: Insert learning curve figure comparing ResNet-18 and Custom CNN

\subsubsection{Comparative Analysis of Phase 1 Models}
Table I provides a comparative overview of the ResNet-18 and custom CNN models based on key performance metrics.

% TODO: Insert Table I: Comparison of ResNet-18 and Custom CNN performance metrics.
% | Model | Parameters | Test Accuracy | Training Time | Best Epoch | Input Size |
% |-------|------------|---------------|---------------|------------|------------|
% | ResNet-18 (Transfer Learning) | 11.7M | 100% | ~11m 20s | 8 | 224x224 |
% | Custom CNN (From Scratch) | 8.6M | 80.67% | ~29m | 47 | 224x224 |

Several key distinctions emerged from this initial comparison:
\begin{itemize}
    \item \textbf{Convergence Speed:} ResNet-18 converged substantially faster (best performance at epoch 8 vs. 47), clearly illustrating the training time advantage conferred by transfer learning.
    \item \textbf{Parameter Efficiency:} The custom CNN utilized fewer parameters (8.6M vs. 11.7M), indicating a more compact architecture despite its respectable performance.
    \item \textbf{Accuracy Discrepancy:} A significant 19.33\% difference in test accuracy highlights the substantial value of pre-trained features for this complex classification task.
    \item \textbf{Training Resources:} Despite its smaller parameter count, the custom CNN demanded more than double the training time compared to the fine-tuned ResNet-18.
\end{itemize}
This initial comparison underscores the fundamental tradeoff: while transfer learning yields superior accuracy and faster convergence, the custom approach offers greater architectural control and provides domain-specific feature learning insights.

\subsection{Phase 2 Results: Architectural Comparison}
Subsequently, Phase 2 involved a systematic comparison of various CNN architectures, facilitated by our flexible experimental framework designed for controlled evaluation.

\subsubsection{Performance Comparison of Architecture Variants}
Table I summarizes the performance metrics for the different architectural variants assessed during Phase 2.

\begin{table}[ht]
\caption{Performance Comparison of CNN Architecture Variants}
\centering
\begin{tabular}{lccccc}
\toprule
\textbf{Model} & \textbf{Test Acc.} & \textbf{F1 Score} & \textbf{Precision} & \textbf{Recall} & \textbf{Training Time} \\
\midrule
ResNet18 & 99.33\% & 0.9933 & 0.9944 & 0.9933 & 32.48 min \\
Deeper CNN & 86.67\% & 0.8567 & 0.8935 & 0.8667 & 36.06 min \\
Base CNN & 85.33\% & 0.8452 & 0.8685 & 0.8533 & 34.96 min \\
Regularized CNN & 81.33\% & 0.8034 & 0.8354 & 0.8133 & 38.39 min \\
Wider CNN & 80.67\% & 0.7973 & 0.8519 & 0.8067 & 62.29 min \\
\bottomrule
\end{tabular}
\end{table}

Key observations derived from this architectural comparison include:
\begin{itemize}
    \item \textbf{ResNet-18 Dominance:} The transfer learning approach consistently maintained a significant performance advantage over all custom-built architectures.
    \item \textbf{Deeper CNN Superiority:} Among the custom models, the Deeper CNN emerged as the top performer (86.67\% test accuracy), suggesting that increased network depth facilitated more effective feature learning for this task compared to other modifications.
    \item \textbf{Base CNN Viability:} The Base CNN provided a solid performance baseline (85.33\%), confirming the fundamental soundness of the initial custom design.
    \item \textbf{Wider CNN Inefficiency:} The Wider CNN, despite requiring the longest training time, yielded the lowest accuracy among custom variants, indicating that simply increasing network width was not an efficient strategy here.
    \item \textbf{Regularization Impact:} The Regularized CNN underperformed relative to the Base CNN, implying that the applied regularization might have been overly restrictive, potentially hindering the model's learning capacity.
\end{itemize}

\subsubsection{Architectural Insights}
This comparative analysis yielded several valuable insights regarding architectural choices:
\begin{itemize}
    \item \textbf{Depth vs. Width:} Increasing network depth proved more beneficial (Deeper: 86.67\%) than increasing width (Wider: 80.67\%), highlighting the importance of hierarchical feature extraction enabled by depth.
    \item \textbf{Regularization Balance:} The results underscore the need for a delicate balance in regularization; the heavily regularized model underperformed, emphasizing the importance of matching regularization strength to model capacity and task complexity.
    \item \textbf{Precision-Recall Tradeoff:} The Deeper CNN exhibited the most favorable balance between precision and recall among custom variants, suggesting a more robust learning process.
    \item \textbf{Complexity vs. Performance:} Although the Deeper CNN required slightly longer training, its superior accuracy justified the additional complexity, indicating effective utilization of architectural depth.
\end{itemize}
Based on these comprehensive findings, the Deeper CNN architecture was selected as the candidate for targeted optimization in the final phase.

\subsection{Phase 3 Results: Deeper CNN Optimization}
Finally, Phase 3 focused on enhancing the performance of the selected Deeper CNN architecture through a suite of targeted optimization techniques.

\subsubsection{Optimized Deeper CNN Performance}
The optimized Deeper CNN achieved a final test accuracy of 93.33\%. This represents a substantial improvement of 6.66\% compared to its Phase 2 performance (86.67\%) and significantly narrows the performance gap relative to the ResNet-18 baseline (99.33\%).

Table II summarizes the key performance metrics for the optimized model.

% TODO: Insert Table II: Performance Metrics of the Optimized Deeper CNN
% | Metric | Value |
% |--------|-------|
% | Test Accuracy | 93.33% |
% | F1 Score (Macro) | 0.9315 |
% | Precision (Macro) | 0.9388 |
% | Recall (Macro) | 0.9333 |
% | Training Time | ~45 min |

\subsubsection{Impact of Optimization Techniques}
The observed performance gains likely resulted from the synergistic effects of the applied optimizations:
\begin{itemize}
    \item \textbf{Selective Attention & Residual Connections:} These architectural refinements likely improved gradient flow and enhanced the model's focus on discriminative features, thereby aiding class differentiation.
    \item \textbf{Graduated Dropout & AdamW:} The refined regularization and optimization strategy likely achieved a better balance between mitigating overfitting and facilitating effective learning, contributing to improved convergence.
    \item \textbf{Class-Specific Augmentation:} Targeting challenging classes (e.g., Alphorn, Flute) with tailored augmentations demonstrably improved their respective F1 scores, consequently boosting overall classification accuracy. (See Figure X).
    \item \textbf{Mixed Precision Training:} This technique accelerated the experimental cycle, enabling more thorough exploration and tuning of hyperparameters.
\end{itemize}

% TODO: Insert Figure X: Comparison of per-class F1 scores before and after Phase 3 optimization.

\subsubsection{Analysis of Challenging Classes}
Despite the significant overall improvement, certain instrument classes remained relatively challenging. Analysis of the confusion matrix (Figure Y) reveals some lingering confusion between visually similar instruments (e.g., certain guitars, woodwinds), although the severity was reduced compared to Phase 2.

% TODO: Insert Figure Y: Confusion matrix for the optimized Deeper CNN.

Notably, the F1 scores for previously identified challenging classes such as Alphorn, Flute, Clarinet, and Didgeridoo showed marked improvement following the targeted optimization phase, validating the effectiveness of the class-specific augmentation strategy.

\subsubsection{Discussion}
The results from Phase 3 demonstrate that systematic and targeted optimization can significantly elevate the performance of custom CNN architectures. The integration of techniques including selective attention, residual connections, advanced regularization, and class-specific augmentation successfully narrowed the performance discrepancy compared to the strong transfer learning baseline. This highlights the potential for custom-designed models to achieve highly competitive results in specialized domains, provided that dedicated refinement and optimization efforts are undertaken.
