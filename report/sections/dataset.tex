% =====================================
% Dataset and Experimental Setup Section
% File: sections/dataset.tex
% =====================================

\section{Dataset and Experimental Setup}
\subsection{Dataset Description}
This study utilizes a comprehensive musical instrument image dataset obtained from Kaggle \cite{gpiosenka2021}. The dataset encompasses 30 distinct musical instrument classes, with images collected from internet searches for each instrument category. To ensure image quality and uniqueness, a duplicate image detector was employed to eliminate redundant samples. All images were standardized to dimensions of 224 × 224 × 3 RGB format and stored in JPG format.

The dataset is organized into three partitions for each instrument class:
\begin{itemize}
    \item Training set: The majority of images for each class
    \item Validation set: 5 images per class
    \item Test set: 5 images per class
\end{itemize}

This partitioning strategy allows for proper model training, hyperparameter tuning, and unbiased performance evaluation. The dataset presents several challenges characteristic of real-world image classification tasks:
\begin{itemize}
    \item Variability in instrument positioning, lighting conditions, and background
    \item Presence of human players in some images, adding occlusion and complexity
    \item Differences in instrument size, color, and manufacturing details
    \item Limited training examples for some instrument classes
\end{itemize}

% TODO: Insert figure showing sample images from different instrument classes
% Figure 1: Sample images from the musical instrument dataset showing the variety
% and challenges in the classification task.

\subsection{Data Preprocessing and Augmentation}
To enhance model robustness and prevent overfitting, we applied several preprocessing and data augmentation techniques:

\begin{itemize}
    \item Normalization: All images were normalized using ImageNet mean and standard deviation values (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    \item Resizing: Images were resized to 224×224 pixels to match the input requirements of the models
    \item Data Augmentation: During training, we applied a series of transformations including random horizontal flips, random rotations (±10°), color jittering, and slight random cropping
\end{itemize}

Data augmentation serves two primary purposes: expanding the effective size of the training set and improving the model's ability to generalize by exposing it to variations not present in the original dataset. This is particularly important for musical instrument classification, where the same instrument may appear in different orientations, lighting conditions, or with slight visual variations.

\subsection{Experimental Setup}
All experiments were conducted using PyTorch, a popular deep learning framework. Models were trained on hardware with GPU acceleration to reduce training time. The following experimental protocols were established for all phases of the project:

\begin{itemize}
    \item Cross-entropy loss as the objective function
    \item Adam optimizer with an initial learning rate of 0.001
    \item Batch size of 32 for all training runs
    \item Early stopping based on validation accuracy with patience of 10 epochs
    \item Accuracy as the primary evaluation metric
\end{itemize}

For the baseline ResNet-18 model, we employed transfer learning by initializing with weights pre-trained on ImageNet. For all custom CNN models, weights were initialized randomly following He initialization \cite{he2015delving}.

To ensure fair comparison between models across all phases, we maintained consistent preprocessing, optimization parameters, and evaluation procedures across all experiments. This consistency is particularly important for Phase 2, where multiple architecture variants are being compared systematically.
